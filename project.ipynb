{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pydicom import dcmread\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patientId</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0004cfab-14fd-4e49-80ba-63a80b6bddd6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00313ee0-9eaa-42f4-b0ab-c148ed3241cd</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00322d4d-1c29-4943-afc9-b6754be640eb</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003d8fa0-6bf1-40ed-b54c-ac657f8495c5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00436515-870c-4b36-a041-de91049b9ab4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00436515-870c-4b36-a041-de91049b9ab4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00569f44-917d-4c86-a842-81832af98c30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>006cec2e-6ce2-4549-bffa-eadfcd1e9970</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00704310-78a8-4b38-8475-49f4573b2dbb</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00704310-78a8-4b38-8475-49f4573b2dbb</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              patientId  Target\n",
       "0  0004cfab-14fd-4e49-80ba-63a80b6bddd6       0\n",
       "1  00313ee0-9eaa-42f4-b0ab-c148ed3241cd       0\n",
       "2  00322d4d-1c29-4943-afc9-b6754be640eb       0\n",
       "3  003d8fa0-6bf1-40ed-b54c-ac657f8495c5       0\n",
       "4  00436515-870c-4b36-a041-de91049b9ab4       1\n",
       "5  00436515-870c-4b36-a041-de91049b9ab4       1\n",
       "6  00569f44-917d-4c86-a842-81832af98c30       0\n",
       "7  006cec2e-6ce2-4549-bffa-eadfcd1e9970       0\n",
       "8  00704310-78a8-4b38-8475-49f4573b2dbb       1\n",
       "9  00704310-78a8-4b38-8475-49f4573b2dbb       1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_data = pd.read_csv('stage_2_train_labels.csv')\n",
    "columns = ['patientId', 'Target']\n",
    "\n",
    "tags_data = tags_data.filter(columns)\n",
    "tags_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27204, 2)\n",
      "(3023, 2)\n"
     ]
    }
   ],
   "source": [
    "training_tags, val_tags = train_test_split(tags_data.values, test_size=0.1)\n",
    "print(training_tags.shape)\n",
    "print(val_tags.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patientId Column: 3e881f10-28aa-4626-a79a-50cc014b7a1a, Target Column: 1\n"
     ]
    }
   ],
   "source": [
    "print(f'patientId Column: {training_tags[0][0]}, Target Column: {training_tags[0][1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Validation Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27204\n",
      "3023\n"
     ]
    }
   ],
   "source": [
    "training_p = 'train_images'\n",
    "testing_p = 'test_images'\n",
    "\n",
    "training_paths = [os.path.join(training_p, image[0]) for image in training_tags]\n",
    "validation_paths = [os.path.join(training_p, image[0]) for image in val_tags]\n",
    "\n",
    "print(len(training_paths))\n",
    "print(len(validation_paths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DS(data.Dataset):\n",
    "    \n",
    "    def __init__(self, paths, tags, transform=None):\n",
    "        self.paths = paths\n",
    "        self.tags = tags\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image = dcmread(f'{self.paths[index]}.dcm')\n",
    "        image = image.pixel_array\n",
    "        image = image / 255.0\n",
    "\n",
    "        image = (255*image).clip(0, 255).astype(np.uint8)\n",
    "        image = Image.fromarray(image).convert('RGB')\n",
    "\n",
    "        tag = self.tags[index][1]\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, tag\n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor:tensor([[[0.1176, 0.1255, 0.1255,  ..., 0.7922, 0.7961, 0.7529],\n",
      "         [0.1255, 0.1294, 0.1333,  ..., 0.8471, 0.8471, 0.8039],\n",
      "         [0.1255, 0.1294, 0.1294,  ..., 0.8431, 0.8431, 0.8000],\n",
      "         ...,\n",
      "         [0.5529, 0.5725, 0.5608,  ..., 0.1255, 0.2706, 0.4510],\n",
      "         [0.5451, 0.5608, 0.5569,  ..., 0.1098, 0.1255, 0.1725],\n",
      "         [0.5059, 0.5137, 0.5137,  ..., 0.1059, 0.1098, 0.1098]],\n",
      "\n",
      "        [[0.1176, 0.1255, 0.1255,  ..., 0.7922, 0.7961, 0.7529],\n",
      "         [0.1255, 0.1294, 0.1333,  ..., 0.8471, 0.8471, 0.8039],\n",
      "         [0.1255, 0.1294, 0.1294,  ..., 0.8431, 0.8431, 0.8000],\n",
      "         ...,\n",
      "         [0.5529, 0.5725, 0.5608,  ..., 0.1255, 0.2706, 0.4510],\n",
      "         [0.5451, 0.5608, 0.5569,  ..., 0.1098, 0.1255, 0.1725],\n",
      "         [0.5059, 0.5137, 0.5137,  ..., 0.1059, 0.1098, 0.1098]],\n",
      "\n",
      "        [[0.1176, 0.1255, 0.1255,  ..., 0.7922, 0.7961, 0.7529],\n",
      "         [0.1255, 0.1294, 0.1333,  ..., 0.8471, 0.8471, 0.8039],\n",
      "         [0.1255, 0.1294, 0.1294,  ..., 0.8431, 0.8431, 0.8000],\n",
      "         ...,\n",
      "         [0.5529, 0.5725, 0.5608,  ..., 0.1255, 0.2706, 0.4510],\n",
      "         [0.5451, 0.5608, 0.5569,  ..., 0.1098, 0.1255, 0.1725],\n",
      "         [0.5059, 0.5137, 0.5137,  ..., 0.1059, 0.1098, 0.1098]]]), Label:1\n"
     ]
    }
   ],
   "source": [
    "training_data = DS(training_paths, training_tags, transform=transform)\n",
    "image = iter(training_data)\n",
    "img, label = next(image)\n",
    "print(f'Tensor:{img}, Label:{label}')\n",
    "img = np.transpose(img, (1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([224, 224, 3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = DS(training_paths, training_tags, transform=transform)\n",
    "val_dataset = DS(validation_paths, val_tags, transform=transform)\n",
    "t_loader = data.DataLoader(dataset=training_data, batch_size=128, shuffle=True)\n",
    "v_loader = data.DataLoader(dataset=val_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = iter(t_loader)\n",
    "img, tags = next(batch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> ResNet18 from Torchvision (Pretrained) - From Pytorch Tutorials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "\n",
    "model.fc = nn.Linear(num_ftrs, 2)\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "213it [12:02,  3.39s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [01:19<00:00,  3.30s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10, Validation Accuracy: 0.7998676896095276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "213it [12:13,  3.45s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [01:22<00:00,  3.43s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/10, Validation Accuracy: 0.8124379515647888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "213it [12:16,  3.46s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [01:22<00:00,  3.46s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/10, Validation Accuracy: 0.8203771114349365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "213it [12:14,  3.45s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [01:20<00:00,  3.36s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/10, Validation Accuracy: 0.8233543038368225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "213it [12:12,  3.44s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [01:19<00:00,  3.30s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5/10, Validation Accuracy: 0.8236851096153259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "213it [11:58,  3.38s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [01:19<00:00,  3.32s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6/10, Validation Accuracy: 0.830962598323822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "213it [11:58,  3.38s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [01:19<00:00,  3.31s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7/10, Validation Accuracy: 0.8286470174789429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "213it [12:27,  3.51s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [01:24<00:00,  3.51s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8/10, Validation Accuracy: 0.8296394348144531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "213it [12:46,  3.60s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [01:24<00:00,  3.52s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9/10, Validation Accuracy: 0.8349322080612183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "213it [12:25,  3.50s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [01:19<00:00,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/10, Validation Accuracy: 0.8428713083267212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "num_step = len(t_loader)\n",
    "\n",
    "for e in range(epochs):\n",
    "    for i, (img, tags) in tqdm(enumerate(t_loader)):\n",
    "        img = img.to(device)\n",
    "        tags = tags.to(device)\n",
    "\n",
    "        res = model(img)\n",
    "        loss = criterion(res, tags)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 2000 == 0:\n",
    "            \n",
    "            print(\"Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}\"\n",
    "                   .format(e+1, epochs, i+1, num_step, loss.item()))\n",
    "\n",
    "\n",
    "    accurate = 0\n",
    "    total = 0  \n",
    "    for img, tags in tqdm(v_loader):\n",
    "        img = img.to(device)\n",
    "        tags = tags.to(device)\n",
    "        pred = model(img)\n",
    "        _, predicted = torch.max(pred, 1)\n",
    "        total += tags.size(0)\n",
    "        accurate += (tags == predicted).sum()\n",
    "    print(f'Epoch: {e+1}/{epochs}, Validation Accuracy: {accurate/total}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [01:19<00:00,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val_Acc: 0.8432021141052246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "accurate = 0\n",
    "total = 0  \n",
    "for img, tags in tqdm(v_loader):\n",
    "    img = img.to(device)\n",
    "    tags = tags.to(device)\n",
    "    pred = model(img)\n",
    "    _, predicted = torch.max(pred, 1)\n",
    "    total += tags.size(0)\n",
    "    accurate += (tags == predicted).sum()\n",
    "print(f'Val_Acc: {accurate/total}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_var=[1,2,3,4,5,6,7,8,9,10]\n",
    "y_var=[79.98, 81.24, 82.03, 82.33, 82.36,83.09, 82.86, 82.96, 83.49, 84.28]\n",
    "plt.plot(x_var, y_var,'b-o',label='Accuracy over 10 epochs')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
